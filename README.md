<div align="center">

<br>
<br>

# ğŸ“ Dialogue Summarization

**KoBART/KoT5 ê¸°ë°˜ ì¼ìƒ ëŒ€í™” ìš”ì•½ ì‹œìŠ¤í…œ**

<br>

# ğŸ… Tech Stack ğŸ…

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)
![Hydra](https://img.shields.io/badge/Hydra-4285F4?style=for-the-badge&logoColor=white)
![WandB](https://img.shields.io/badge/W&B-FFBE00?style=for-the-badge&logo=weightsandbiases&logoColor=black)

</div>

<br>

## ğŸ‘¥ Team

| ![ë¬¸êµ­í˜„](https://github.com/GH-Door.png) | ![ë¥˜ì§€í—Œ](https://github.com/mahomi.png) | ![ì´ìŠ¹í˜„](https://github.com/shyio06.png) | ![ì •ì¬í›ˆ](https://github.com/coevol.png) | ![ì¡°ì„ ë¯¸](https://github.com/LearnSphere-2025.png) | ![ì´ë‚˜ê²½](https://github.com/imnaagyeong.png) | ![ì´ì¤€ì„](https://github.com/Lee-0624.png) |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| [ë¬¸êµ­í˜„](https://github.com/GH-Door) | [ë¥˜ì§€í—Œ](https://github.com/mahomi) | [ì´ìŠ¹í˜„](https://github.com/shyio06) | [ì •ì¬í›ˆ](https://github.com/coevol) | [ì¡°ì„ ë¯¸](https://github.com/LearnSphere-2025) | [ì´ë‚˜ê²½](https://github.com/imnaagyeong) | [ì´ì¤€ì„](https://github.com/Lee-0624) |
| íŒ€ì¥ | íŒ€ì› | íŒ€ì› | íŒ€ì› | íŒ€ì› | íŒ€ì› | íŒ€ì› |

<br>

## Project Overview

| í•­ëª© | ë‚´ìš© |
|:-----|:-----|
| **ğŸ“… Date** | 2025.07 ~ 2025.08 |
| **ğŸ‘¥ Type** | íŒ€ í”„ë¡œì íŠ¸ (Upstage AI Lab) |
| **ğŸ¯ Goal** | ì¼ìƒ ëŒ€í™” ìš”ì•½ ëª¨ë¸ ê°œë°œ ë° Multi-Model Ensembleì„ í†µí•œ ì„±ëŠ¥ ìµœì í™” |
| **ğŸ”§ Tech Stack** | PyTorch, Transformers, Hydra, WandB, KoBART, KoT5 |
| **ğŸ“Š Dataset** | ì¼ìƒ ëŒ€í™” ìš”ì•½ ë°ì´í„°ì…‹ (Train 12,457 / Dev 499 / Test 250) |
| **ğŸ† Result** | **9íŒ€ ì¤‘ 2ìœ„** (ROUGE-L 49.69 Mid / 46.54 Final) |

<br>

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ì†Œê°œ](#-í”„ë¡œì íŠ¸-ì†Œê°œ)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [ë¬¸ì œ í•´ê²° ê³¼ì •](#-ë¬¸ì œ-í•´ê²°-ê³¼ì •)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#-í”„ë¡œì íŠ¸-êµ¬ì¡°)

<br>

---

## ğŸ¯ í”„ë¡œì íŠ¸ ì†Œê°œ

ì¼ìƒ ëŒ€í™”(í•™êµ, ì§ì¥, ì‡¼í•‘, ì—¬í–‰ ë“±)ë¥¼ ìë™ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” NLP ëª¨ë¸ ê°œë°œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. **KoBART** ë° **KoT5** ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ Fine-tuningí•˜ê³ , **WandB Bayesian Sweep**ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•œ ë’¤, **5ê°€ì§€ ì•™ìƒë¸” ê¸°ë²•**ì„ ë¹„êµí•˜ì—¬ ìµœì¢… **9íŒ€ ì¤‘ 2ìœ„**ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•
- ğŸ“ **Multi-Model Ensemble**: 8ê°œ ëª¨ë¸ Logit Beam Search ì•™ìƒë¸”ë¡œ ë¦¬ë”ë³´ë“œ ê°±ì‹ 
- âš™ï¸ **ì„¤ì • ì¤‘ì‹¬ ì„¤ê³„**: Hydraë¥¼ í†µí•œ ì‹¤í—˜ë³„ config ê´€ë¦¬
- ğŸ“Š **WandB Bayesian Sweep**: ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë° ì‹¤í—˜ ì¶”ì 
- ğŸ”„ **5ê°€ì§€ ì•™ìƒë¸” ì „ëµ**: Hard Voting, Score-based, Length-based, Logit Beam Search, Logit Greedy

<br>

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    A[ì¼ìƒ ëŒ€í™” ë°ì´í„°] --> B[ë°ì´í„° ì „ì²˜ë¦¬]
    B --> C[Special Token ì¶”ê°€]
    C --> D[KoBART / KoT5 Fine-tuning]
    D --> E[WandB Bayesian Sweep]
    E --> F[8ê°œ ìµœì í™” ëª¨ë¸]
    F --> G[5ê°€ì§€ ì•™ìƒë¸” ì¶”ë¡ ]
    G --> H[ìµœì¢… ìš”ì•½ë¬¸ ìƒì„±]
```

### Training & Inference Pipeline
```python
# Hydra ê¸°ë°˜ ì„¤ì • ê´€ë¦¬
@hydra.main(config_path="conf", config_name="config")
def main(cfg: DictConfig):
    model, tokenizer = load_tokenizer_and_model_for_train(cfg)
    trainer = load_trainer_for_train(cfg, model, tokenizer, train_dataset, val_dataset)
    trainer.train()
    output = inference(cfg)
```

<br>

## ğŸ”§ ë¬¸ì œ í•´ê²° ê³¼ì •

### 1ï¸âƒ£ ë‹¨ì¼ ëª¨ë¸ Fine-tuning ì„±ëŠ¥ í•œê³„
> KoBART ë‹¨ì¼ ëª¨ë¸ Fine-tuningë§Œìœ¼ë¡œëŠ” ROUGE-L 48.04(Mid)ì— ê·¸ì¹¨. ëŒ€í™”ì²´ì˜ ë‹¤ì–‘í•œ í‘œí˜„ê³¼ ë§¥ë½ì„ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì¶©ë¶„íˆ í•™ìŠµí•˜ê¸° ì–´ë ¤ì›€

**í•´ê²°:** **WandB Bayesian Sweep**ìœ¼ë¡œ Learning Rate, Batch Size, Beam Search ë“± í•µì‹¬ íŒŒë¼ë¯¸í„°ë¥¼ ìë™ ìµœì í™”í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ í•™ìŠµí•œ **8ê°œ ëª¨ë¸** ìƒì„±. ê° ëª¨ë¸ì´ ì„œë¡œ ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ëŒ€í™” ìš”ì•½ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì„ í¬ì°©

---

### 2ï¸âƒ£ ìµœì ì˜ ì•™ìƒë¸” ì „ëµ ì„ ì •
> ì—¬ëŸ¬ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ê²°í•©í•˜ëŠ” ë°©ë²•ì— ë”°ë¼ ì„±ëŠ¥ ì°¨ì´ê°€ í¬ê²Œ ë°œìƒ. Post-Generation ë°©ì‹(Hard Voting, Score-based ë“±)ê³¼ Real-time ë°©ì‹(Logit ê¸°ë°˜) ê°„ ë¹„êµ í•„ìš”

**í•´ê²°:** **5ê°€ì§€ ì•™ìƒë¸” ê¸°ë²•**ì„ ì²´ê³„ì ìœ¼ë¡œ êµ¬í˜„ ë° ë¹„êµ. **Logit Beam Search**(ê° ìŠ¤í…ì—ì„œ ëª¨ë“  ëª¨ë¸ì˜ í™•ë¥  ë¶„í¬ë¥¼ ê²°í•©í•˜ì—¬ ìƒìœ„ kê°œ ë¹” ìœ ì§€)ê°€ ROUGE-avg 0.2969ë¡œ **1ìœ„** ë‹¬ì„±, ê¸°ì¡´ ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ í–¥ìƒ í™•ì¸

---

### 3ï¸âƒ£ ë°ì´í„° ì¦ê°• íš¨ê³¼ ê²€ì¦
> AEDA ê¸°ë°˜ ê·œì¹™ì  ë°ì´í„° ì¦ê°•(êµ¬ë‘ì  ì‚½ì…, ìœ ì˜ì–´ êµì²´ ë“±)ì„ ì‹œë„í–ˆìœ¼ë‚˜ ì„±ëŠ¥ í–¥ìƒ ë¯¸ë¯¸

**í•´ê²°:** AEDA 2ëª¨ë¸ ì•™ìƒë¸”(49.52 Mid)ê³¼ ì¦ê°• ì—†ëŠ” 3ëª¨ë¸ ì•™ìƒë¸”(49.69 Mid)ì„ ë¹„êµí•˜ì—¬, **ë‹¨ìˆœ ê·œì¹™ ê¸°ë°˜ ì¦ê°•ë³´ë‹¤ ëª¨ë¸ ë‹¤ì–‘ì„± í™•ë³´ê°€ ë” íš¨ê³¼ì **ì„ì„ ì‹¤í—˜ì ìœ¼ë¡œ ì…ì¦. ì´í›„ ëª¨ë¸ ìˆ˜ ì¦ê°€ì™€ ì•™ìƒë¸” ì „ëµ ìµœì í™”ì— ì§‘ì¤‘

<br>

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
nlp_summarization/
â”œâ”€â”€ main.py                        # ë©”ì¸ ì§„ì…ì  (Hydra ê¸°ë°˜)
â”œâ”€â”€ conf/                          # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ config.yaml               # ë©”ì¸ ì„¤ì •
â”‚   â”œâ”€â”€ model/                    # ëª¨ë¸ ì„¤ì •
â”‚   â”œâ”€â”€ data/                     # ë°ì´í„° ì„¤ì •
â”‚   â”œâ”€â”€ training/                 # í•™ìŠµ ì„¤ì • (Epochs, LR, Scheduler ë“±)
â”‚   â””â”€â”€ inference/                # ì¶”ë¡  ì„¤ì • (Beam Search, Max Length ë“±)
â”œâ”€â”€ src/                           # í•µì‹¬ ì†ŒìŠ¤ì½”ë“œ
â”‚   â”œâ”€â”€ data.py                   # ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ model.py                  # ëª¨ë¸ ë¡œë“œ (KoBART/KoT5)
â”‚   â”œâ”€â”€ train.py                  # Seq2SeqTrainer í•™ìŠµ ë¡œì§
â”‚   â”œâ”€â”€ inference.py              # ì¶”ë¡  íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ preprocess.py             # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ utils.py                  # ë¡œê¹… ìœ í‹¸ë¦¬í‹°
â”‚   â””â”€â”€ check_gpu.py              # GPU ë””ë°”ì´ìŠ¤ í™•ì¸
â”œâ”€â”€ ensemble/                      # ì•™ìƒë¸” ì¶”ë¡ 
â”‚   â”œâ”€â”€ ensemble_inference.py     # 5ê°€ì§€ ì•™ìƒë¸” ê¸°ë²• êµ¬í˜„
â”‚   â””â”€â”€ ensemble_inference_best.py # ìµœì  ì•™ìƒë¸” (ë¦¬ë”ë³´ë“œ ê°±ì‹ )
â”œâ”€â”€ sweep/                         # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
â”‚   â”œâ”€â”€ wandb_sweep.py            # WandB Bayesian Sweep
â”‚   â””â”€â”€ solar_api_sweep.py        # Solar API íŒŒë¼ë¯¸í„° Sweep
â”œâ”€â”€ augmentation/                  # ë°ì´í„° ì¦ê°•
â”‚   â”œâ”€â”€ aeda_augmentation.py      # AEDA ì¦ê°•
â”‚   â””â”€â”€ data_augmentation.py      # ë²”ìš© ë°ì´í„° ì¦ê°•
â”œâ”€â”€ notebooks/                     # ë¶„ì„ ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ EDA.ipynb                 # íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
â”‚   â””â”€â”€ eda_preprocessing.ipynb   # ì „ì²˜ë¦¬ ë¶„ì„
â”œâ”€â”€ data/                          # ë°ì´í„°ì…‹
â””â”€â”€ pyproject.toml                 # í”„ë¡œì íŠ¸ ì„¤ì •
```

<br>

## ğŸ“ License

This project is licensed under the MIT License.

---

<div align="center">

**ğŸ“ Dialogue Summarization**
*Powered by KoBART & Multi-Model Ensemble*

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.7+-red.svg)](https://pytorch.org/)

Made with ğŸ“ by NLP Summarization Team

</div>

---
